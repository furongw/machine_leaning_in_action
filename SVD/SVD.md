# SVD

奇异值分解（Singular Value Decomposition,SVD）

- 优点：简化数据，去除噪声和冗余信息，提高算法的结果
- 缺点：数据的转换可能难以理解，会降低程序的速度
- 适用数据类型：数值型数据

SVD的两个应用：
- 信息检索

利用SVD的方法为隐性语义索引（LSI）或隐性语义分析（LSA）。
解决只基于词语存在与否的简单搜索方法不能解决的词语拼写错误、同义词的问题

- 推荐系统
先利用SVD从数据中构建一个主题空间，然后再在该空间下计算其相似度

> [奇异值与特征值](<https://blog.csdn.net/songer93/article/details/80761450>)

线性代数该好好复习下了QAQ

SVD将原始的数据集矩阵Data分解成三个矩阵$u$、$\sum$和$V^T$如果原始数据是m行n列，这三者就分别是m行m列，m行n列和n行n列。
$$
Data_{m\times n}=U_{m\times m}\sum_{m\times n}V^T_{n\times n}
$$
$\sum$矩阵只有对角元素，其它元素均为0.从大到小排列。这些对角元素称为奇异值。奇异值就是矩阵$Data*Data^{T}$的平方根。在某个奇异值之后（r个），其他的奇异值都置为0。这就意味着数据集中仅有r个重要特征，而其余特征则都是噪声或冗余特征。

计算相似度（距离）：

- 欧式距离

此时
$$
相似度=\frac{1}{1+距离}
$$

- 皮尔逊相关系数

corrcoef().相对于欧式距离，它对于用户的评级不敏感

- 余弦相似度

$$
cos\theta=\frac{A\cdot B}{||A||||B||}
$$

np.linalg.norm可计算范数



推荐引擎的评价：

最小均方根误差(Root Mean Squared Error,RMSE)。首先计算均方误差的平均值然后取平方根。

**冷启动**问题：如何在缺乏数据时给出好的推荐。

>也就是说，在协同过滤场景下，由于新物品到来时由于缺乏所有用户对其的喜好信息，因此无法判断每个用户对其的喜好。而无法判断某个用户对其的喜好，也就无法利用该商品。



